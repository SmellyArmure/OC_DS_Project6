{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Brouillons.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNW2SIdtCT93DNdgvkSILUa"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"dIPayvsF5WeB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X48Qm8Z_5YuK"},"source":["# IDEES A IMPLEMENTER"]},{"cell_type":"markdown","metadata":{"id":"46WEoAjP5css"},"source":["#### overview des mots de l'ensemble du corpus"]},{"cell_type":"code","metadata":{"id":"htMG_DEV5Xfa"},"source":["# Graph top tags\n","\n","# inputs\n","top_n = 50   # number of tag to display\n","df_1 = pd.DataFrame(all_tags.most_common(), columns=[\"tags\",\"freq_all\"])\n","\n","#plot\n","fig = plt.figure(figsize=(15,10))\n","\n","# hist\n","plt.subplot(1,2,1)\n","plt.title(\"Top tags by frequency\", fontweight=\"bold\", size=20)\n","sns.barplot(x= \"freq_all\", y= \"tags\", data= df_1.loc[0:top_n, :], label=\"Total\")\n","plt.yticks(rotation=0, size=13)\n","plt.ylabel(\"Tags\", size=16)\n","plt.xlabel(\"Tags frequency [number of occurences]\", size=16)\n","\n","# word cloud Graph\n","plt.subplot(1,2,2)\n","wordcloud = WordCloud(width=375,\n","                      height=600,\n","                      max_words=1628,\n","                      relative_scaling=1,\n","                      normalize_plurals=False,\n","                      background_color=\"white\").generate_from_frequencies(dict(all_tags.most_common(400)))\n","\n","plt.imshow(wordcloud, interpolation='bilinear')\n","plt.axis(\"off\")\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kr5YU2pI75YG"},"source":["#### Graphe des occurences des mots du titre en fonction de ceux des mots de la description"]},{"cell_type":"code","metadata":{"id":"RsbIqrLB5Xh5"},"source":["# Relation in-between frequency for top tags versus primary tags \n","\n","#inputs\n","df_2 = pd.DataFrame(primary_tags.most_common(), columns=[\"tags\",\"freq_primary\"])  \n","df = pd.merge(df_1, df_2, how=\"left\" )\n","\n","# plot\n","plt.figure(figsize=(10, 10))\n","plt.title(\"Frequency: Top tags versus Primary tags\", fontweight=\"bold\", size = 20)\n","sns.plt.scatter(x=\"freq_all\", y=\"freq_primary\", data=df, alpha=0.5)\n","\n","# text annotations\n","for i in range(0,18):\n","    plt.annotate(df.loc[i,\"tags\"],\n","                 (df.loc[i,\"freq_all\"]+200, df.loc[i,\"freq_primary\"]+50),\n","                 size=15)\n","\n","# unity line\n","u = np.linspace(0,17500,10)\n","plt.plot(u,u, c=\"red\")\n","plt.plot(u,u*0, c=\"blue\")\n","    \n","plt.xlabel(\"Top tags frequency [number of occurences]\", size=16)\n","plt.ylabel(\"Primary tags frequency [number of occurences]\", size=16)\n","plt.show() "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kR5iGrf38TST"},"source":["#### Somme cumulée des fréquences des mots les plus utilisés (à faire avec le product_name et avec les descriptions pour avoir une intuition du nb de mots à conserver...."]},{"cell_type":"code","metadata":{"id":"Galtfqhe5Xm8"},"source":["# Input\n","cumsum = 100*df.loc[:, \"freq_all\"].cumsum()/df[\"freq_all\"].sum()\n","mask = cumsum > 50          # we want at least 50% of the occurence\n","n_tag = cumsum.loc[mask].argmin()\n","x = np.linspace(0, 500, 10)\n","\n","# plot\n","plt.figure(figsize=(10,7))\n","plt.plot(cumsum)\n","plt.axhline(y=50, xmax=n_tag/500, color='r', linestyle=':')\n","plt.axvline(x=n_tag, ymax=50/80, color='r', linestyle=':')\n","plt.xlim(-3,500)\n","plt.ylim(0,80)\n","plt.title(\"Normalised cumulative sum of top tags occurence\", fontweight=\"bold\", size=20)\n","plt.xlabel(\"Number of top tags\", size=16)\n","plt.ylabel(\"Normalised occurence cumulative sum [%]\", size=16)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7gYFWB579S7o"},"source":["#### Affichage avec PyLDAvis"]},{"cell_type":"code","metadata":{"id":"sfygXb625Xsa"},"source":["# plot with PyLDAvis library\n","import pyLDAvis.sklearn\n","\n","pyLDAvis.enable_notebook()\n","panel = pyLDAvis.sklearn.prepare(lda_tfidf_uns, tfidf, tfidf_vectorizer, mds='tsne')\n","panel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rce9G_VL5XyI"},"source":["%matplotlib inline\n","import pyLDAvis\n","import pyLDAvis.gensim\n","vis = pyLDAvis.gensim.prepare(topic_model=lda_model, corpus=corpus, dictionary=dictionary_LDA)\n","pyLDAvis.enable_notebook()\n","pyLDAvis.display(vis)\n","\n","vis = pyLDAvis.gensim.prepare(topic_model=lda_model, corpus=corpus, dictionary=dictionary_LDA)\n","pyLDAvis.enable_notebook()\n","pyLDAvis.display(vis)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eeDtxMlIALL0"},"source":["### Voir davidjulienmillet pour l'affichage des descripteurs SIFT !!!"]},{"cell_type":"code","metadata":{"id":"qXdBnaL-5X3P"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bK6ExwSf5X-q"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7NlcCnWa5YCO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s0wBCnrP5X8V"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"El44agpg5X6t"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jMInil3A5X1i"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EAcgB3WX5XwO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wqb_wKX-5Xqf"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gPxoQr6k5XlP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sxaj1pdB6l-p"},"source":["# Version qui marche mais la sortie de .cv_results_ n'a pas le même format qu'un\n","# gridsearch standard\n","\n","'''\n","Class to optimize clustering score.\n","Instantiate with a clusterer (estimator), a grid parameter (param_grid)\n","and a scoring function or a dictionary of functions (scoring)\n","'''\n","\n","import numpy as np\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.model_selection import ParameterGrid\n","\n","class GridSearchClust(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self, estimator, param_grid_estim, param_grid_preproc=None,\n","                 scoring=None, refit=silhouette_score, greater_is_better=True):\n","\n","        # Getting parameters\n","        self.estimator = estimator\n","        self.param_grid_estim = param_grid_estim\n","        self.param_grid_preproc = param_grid_preproc\n","        self.scoring = scoring\n","        self.refit = refit\n","        self.greater_is_better = greater_is_better\n","\n","    def fit(self, X, verbose=False):\n","\n","        # Initialization of the dict of results\n","        self.results_ = {\"scores\": [],\n","                         \"params\": [],\n","                         \"models\": [],\n","                        #  \"fit_times\": [],\n","                         \"nb_clusters\": [],\n","                         \"refit_score\": []}\n","\n","        # iterating upon all combinations of parameters\n","        for param in ParameterGrid(self.param_grid_estim):\n","\n","            # instanciation of the model with selected parameters\n","            model = self.estimator.set_params(**param)\n","\n","            # fitting the model\n","            model.fit(X)\n","\n","            # computing labels\n","            labels = model.labels_\n","\n","            # # Measuring training time while fitting the model on the data\n","            # time_train = %timeit -n1 -r1 -o -q model.fit(X)\n","            # time_train = time_train.average\n","\n","            # Refit score\n","            try:\n","                refit_score = self.refit(X, labels) # self.scoring['silh'](X, labels)\n","            except:\n","                refit_score = np.nan\n","            \n","            # Other scores (scoring)\n","            model_score = {}\n","            if not self.scoring:  # if scoring parameter not defined\n","                model_score['score'] = model.score(X) # default score\n","            else:  # if scoring parameter is defined\n","                if type(self.scoring) != dict:\n","                    self.scoring = {'score': self.scoring}\n","                else:\n","                    for n_sco, sco in self.scoring.items():\n","                        try:\n","                            model_score[n_sco] = sco(X, labels)\n","                        except:\n","                            model_score[n_sco] = np.nan\n","            if verbose: print(model_score)\n","            \n","            # Computing number of clusters, excluding noise (#-1)\n","            nb_clusters = \\\n","                len(set(model.labels_)) - (1 if -1 in set(model.labels_) else 0)\n","            nb_clusters = int(nb_clusters)\n","            if verbose: print(nb_clusters)\n","\n","            # saving results, parameters and models in a dict\n","            self.results_[\"refit_score\"].append(refit_score)  # refit score\n","            self.results_[\"scores\"].append(model_score)  # dict of scores\n","            self.results_[\"params\"].append(param)  # parameters\n","            self.results_[\"models\"].append(model)  # trained models\n","            # self.results_[\"fit_times\"].append(time_train)  # training time\n","            self.results_[\"nb_clusters\"].append(nb_clusters)  # nb of clusters\n","        \n","        # Selecting best model based on the refit_score\n","        # -----------------------------------\n","        # initialisation\n","        best_model_index, best_score = None, None  \n","        # iterating over scores\n","        for index, score in enumerate(self.results_[\"refit_score\"]):\n","\n","            # initialisation\n","            if not best_score:\n","                best_score = score\n","                best_model_index = index\n","\n","            # if score is better than current best_score\n","            cond = score > best_score if self.greater_is_better\\\n","                                                 else score < best_score\n","            if cond:\n","                    # update the current best_score and current best_model_index\n","                    best_score = score\n","                    best_model_index = index\n","        \n","        # Update attributes of the instance\n","        self.best_refit_score_ = self.results_[\"refit_score\"][best_model_index]\n","        self.best_score_ = self.results_[\"scores\"][best_model_index]\n","        self.best_params_ = self.results_[\"params\"][best_model_index]\n","        self.best_estimator_ = self.results_[\"models\"][best_model_index]\n","        self.best_index_ = best_model_index\n","        # self.refit_time_ = self.results_[\"fit_times\"][best_model_index]\n","\n","        # refit the best model\n","        self.best_estimator_.fit(X)\n","        \n","        return self\n","\n","    def predict(self, X_test):\n","\n","        # use the .predict method of the estimator on the best model\n","        return self.best_model.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zMystkVcY6Vq"},"source":["#### REGRESSEUR AVEC GRIDSEARCH POUR MEMOIRE\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import GridSearchCV\n","from random import randint\n","from sklearn import metrics\n","\n","df_X = pd.DataFrame({'a': np.arange(1000)+randint(0,1000)/100,\n","                    'b': np.arange(1000,2000)+randint(0,1000)/100})\n","df_y = pd.Series(np.arange(50,1050)+randint(0,1000)/100)\n","ss = StandardScaler()\n","lreg = LinearRegression()\n","\n","pipe_reg = Pipeline([('preproc', ss),\n","                     ('reg', lreg)])\n","\n","params = {'reg__fit_intercept': [True, False],\n","          'reg__normalize': [True, False]}\n","\n","# Mean Absolute Error\n","def calc_mae(y, ypr):\n","    return metrics.mean_absolute_error(y, ypr)\n","def calc_mae_log(y_log, y_log_pr):\n","    y = np.exp(y_log)-1\n","    ypr = np.exp(y_log_pr)-1\n","    return metrics.mean_absolute_error(y, ypr)\n","# Root Mean Squared Error\n","def calc_rmse(y, ypr):\n","    return np.sqrt(metrics.mean_squared_error(y, ypr))\n","def calc_rmse_log(y_log, y_log_pr):\n","    y = np.exp(y_log)-1\n","    ypr = np.exp(y_log_pr)-1\n","    return np.sqrt(metrics.mean_squared_error(y, ypr))\n","mae = metrics.make_scorer(calc_mae, greater_is_better=False)\n","rmse = metrics.make_scorer(calc_rmse, greater_is_better=False) \n","\n","gscv = GridSearchCV(pipe_reg,\n","                    param_grid=params,\n","                    scoring={'mae': mae,\n","                             'mse': rmse},\n","                    refit='mse'\n","                    )\n","gscv.fit(df_X.values, df_y.values)"],"execution_count":null,"outputs":[]}]}