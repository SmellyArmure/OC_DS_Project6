{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"P6_Cleaning_PICT_old.ipynb","provenance":[{"file_id":"1T1ZdFO9lxPjkqpb6QlvX1GDPbV1zi2cM","timestamp":1602668765222},{"file_id":"1qAxkvKD2odWAQUnotM2Dwijh45Ko0iCO","timestamp":1587461379791},{"file_id":"1wX6ZnTUKkvXaWwnL6E51NNuJkxEdSK-h","timestamp":1582132452639},{"file_id":"144JCi9-nMiX9eD3AccG2sgaTbug2wQTa","timestamp":1581758429991},{"file_id":"1kRjoSOVhLf1GbPOY6C2MGdpHdjUsJGe1","timestamp":1581430098593},{"file_id":"1SzuDOE2ejfYYNHpdu1hTrvQZd5phpvyP","timestamp":1581092731309},{"file_id":"1NHY7TNgChDa8i5eggkSxZV133o6RB2pP","timestamp":1580472396109},{"file_id":"1CjFqLqI3e83aWkErpy2_tDoqWWSc5V7K","timestamp":1567509524556},{"file_id":"1oFtNqY9sTtyX09HnsLY5GOpchE7TWSLc","timestamp":1567440734485},{"file_id":"1kO3qnFJ8XAhA2WzueAy6Gwr0KwfoSF2z","timestamp":1566893631574},{"file_id":"1rI7P6dn7-IGK6p8HX7dvNP93roGSzXeX","timestamp":1566833630097},{"file_id":"1cAbXwtjxfOIVmnecCFlHrVryskoYJCXA","timestamp":1566734390006},{"file_id":"https://github.com/SmellyArmure/PROJECT3/blob/master/NOTEBOOKS/P3_Cleaning_v1_0.ipynb","timestamp":1566726579304}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"pVbrKjWrGl4m"},"source":["# \"Classifiez automatiquement des biens de consommation\"\n","_NLP Cleaning Notebook_"]},{"cell_type":"markdown","metadata":{"id":"AXy2xt5wB3ZD"},"source":["## 0 Preliminaries"]},{"cell_type":"markdown","metadata":{"id":"NQ8_ZaJvGl4o"},"source":["### 0.0 Importing Packages and Modules"]},{"cell_type":"code","metadata":{"id":"Bp0BR8mhTyiD","colab":{"background_save":true}},"source":["# !apt install sudo\n","# !sudo apt-get update\n","# !sudo apt-get upgrade\n","# !sudo apt update\n","# !apt list --upgradable\n","# !sudo apt upgrade\n","# !apt list --upgradable\n","# !sudo apt upgrade\n","# %cd /content\n","# !sudo apt remove cmake\n","# !sudo apt purge --auto-remove cmake\n","# !mkdir ~/temp\n","# %cd ~/temp\n","# !wget https://cmake.org/files/v3.12/cmake-3.12.3-Linux-x86_64.sh\n","# !sudo mkdir /opt/cmake\n","# !sudo sh cmake-3.12.3-Linux-x86_64.sh --prefix=/opt/cmake --skip-license\n","# !sudo ln -s /opt/cmake/bin/cmake /usr/local/bin/cmake\n","# %cd /content\n","# !sudo apt-get install libopenblas-dev liblapack-dev \n","# !sudo apt-get install libx11-dev libgtk-3-dev\n","# !sudo apt-get install libboost-all-dev"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XKUzl6mHOcZa"},"source":["Checking whether the notebook is on Colab or PC"]},{"cell_type":"code","metadata":{"id":"S7MAxokr4UmP","executionInfo":{"elapsed":4372,"status":"ok","timestamp":1602763086637,"user":{"displayName":"Maryse Muller","photoUrl":"","userId":"13230828717959946182"},"user_tz":-120},"outputId":"647c4ca4-3a15-4d4d-ede1-4dba662487e9","colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["import sys\n","is_colab = 'google.colab' in sys.modules\n","is_colab, sys.executable"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(True, '/usr/bin/python3')"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"g9oJU8UHOaRC"},"source":["Mounting my Drive if on Colab"]},{"cell_type":"code","metadata":{"id":"l5RrOSXvfGrC","executionInfo":{"elapsed":4322,"status":"ok","timestamp":1602763086638,"user":{"displayName":"Maryse Muller","photoUrl":"","userId":"13230828717959946182"},"user_tz":-120},"outputId":"96be9f02-c646-4d41-bdbd-59f95873a5af","colab":{"base_uri":"https://localhost:8080/","height":66}},"source":["if is_colab==True:\n","    from google.colab import files, output, drive\n","    drive.mount('/gdrive')\n","    %cd /gdrive\n","    print(\"You're on Google Colab\")\n","else:\n","    print(\"You're on a PC\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n","/gdrive\n","You're on Google Colab\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"F7E_-Zd9OgY7"},"source":["Installations and importations required in the virtual environment."]},{"cell_type":"code","metadata":{"id":"VZ__n1yHHrQJ"},"source":["import os\n","if os.getcwd()!='/gdrive/My Drive/--DATA SCIENCE/PROJET6/NOTEBOOKS':\n","    os.chdir('/gdrive/My Drive/--DATA SCIENCE/PROJET6/NOTEBOOKS')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5J3FEp0fqFrg"},"source":["# !pip install -r requirements_pict.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x1xzfQL5OvRk"},"source":["from P6_functions import *"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gvdHBoIuH90C"},"source":["Installations (creating the requirements file)"]},{"cell_type":"code","metadata":{"id":"H1oa9ebJHSOm","executionInfo":{"elapsed":14237,"status":"ok","timestamp":1602763096621,"user":{"displayName":"Maryse Muller","photoUrl":"","userId":"13230828717959946182"},"user_tz":-120},"outputId":"eb0b899e-7f00-48a4-e05e-1f344136b91a","colab":{"base_uri":"https://localhost:8080/","height":423}},"source":["!pip install gtts\n","!pip install wikipedia2vec==0.2.2\n","!pip install opencv-contrib-python==3.4.2.17\n","!pip install opencv-python==3.4.2.17"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gtts in /usr/local/lib/python3.6/dist-packages (2.1.1)\n","Requirement already satisfied: gtts-token>=1.1.3 in /usr/local/lib/python3.6/dist-packages (from gtts) (1.1.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gtts) (2.23.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from gtts) (4.6.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gtts) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from gtts) (7.1.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (3.0.4)\n","Requirement already satisfied: wikipedia2vec==0.2.2 in /usr/local/lib/python3.6/dist-packages (0.2.2)\n","Requirement already satisfied: marisa-trie in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec==0.2.2) (0.7.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec==0.2.2) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec==0.2.2) (1.18.5)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec==0.2.2) (0.16.0)\n","Requirement already satisfied: lmdb in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec==0.2.2) (0.99)\n","Requirement already satisfied: mwparserfromhell in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec==0.2.2) (0.5.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec==0.2.2) (1.4.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec==0.2.2) (4.41.1)\n","Requirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec==0.2.2) (0.42.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec==0.2.2) (1.15.0)\n","Requirement already satisfied: opencv-contrib-python==3.4.2.17 in /usr/local/lib/python3.6/dist-packages (3.4.2.17)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-contrib-python==3.4.2.17) (1.18.5)\n","Requirement already satisfied: opencv-python==3.4.2.17 in /usr/local/lib/python3.6/dist-packages (3.4.2.17)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==3.4.2.17) (1.18.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gQ-WJqLWFtzu"},"source":["# !pip freeze > requirements_pict.txt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xBgiuFEdQq78"},"source":["Importation of modules and packages. "]},{"cell_type":"code","metadata":{"id":"oDhE9utOlwJe"},"source":["import io\n","\n","import string\n","\n","import pandas as pd\n","import seaborn as sns\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","plt.rcParams['figure.facecolor']='w'\n","\n","# import warnings\n","# warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xNSTytWrQ0De"},"source":["Setting pandas display options."]},{"cell_type":"code","metadata":{"id":"G0rRvyJaWO2h"},"source":["dictPdSettings = {'display.max_rows': 500, 'display.width': 100,\n","                  'display.max_colwidth': 100,\n","                  'display.float_format': lambda x: '%.2f' % x}\n","for k,v in dictPdSettings.items():\n","  pd.set_option(k,v)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z9APZjLzQ_sp"},"source":["To play audio text-to-speech during execution."]},{"cell_type":"code","metadata":{"id":"vgvmjvZ_Y6-s"},"source":["# from IPython.display import Audio\n","# from gtts import gTTS\n","\n","# def speak(text, lang='en'):\n","#     with io.BytesIO() as f:\n","#         gTTS(text=text, lang=lang).write_to_fp(f)\n","#         f.seek(0)\n","#         return Audio(f.read(), autoplay=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X5b_ibTl83bD"},"source":["# speak('Packages and modules successfully imported')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fmDu0rMFGl5A"},"source":["### 0.1 Importing the datasets"]},{"cell_type":"markdown","metadata":{"id":"R_c4YLdXQAzn"},"source":["Data is composed of 9 distinct .csv files we'll load in a dictionnary of dataframes."]},{"cell_type":"code","metadata":{"id":"KhVW-wxr30Ia","executionInfo":{"elapsed":14482,"status":"ok","timestamp":1602763096982,"user":{"displayName":"Maryse Muller","photoUrl":"","userId":"13230828717959946182"},"user_tz":-120},"outputId":"f7a83943-e691-4b6f-a3be-246534056000","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["if is_colab==True:\n","    # Importing database from my Drive\n","    print(\"Try to import data files in the notebook from myDrive...\")\n","else:\n","    # Importing database from PC\n","    print(\"Try to import data files in the notebook from PC ('DATA')...\")\n","\n","df = pd.read_csv(\"../DATA/flipkart_com-ecommerce_sample_1050.csv\",\n","                 sep=',', \n","                 index_col = 'uniq_id',\n","                 encoding ='utf-8')\n","\n","print(\"-----> Importation of .csv in the notebook: OK\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Try to import data files in the notebook from myDrive...\n","-----> Importation of .csv in the notebook: OK\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"61owD2pedhh5"},"source":["# speak('Datasets successfully imported')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aa7i2NpD0U_h"},"source":["### 0.2 Categories"]},{"cell_type":"code","metadata":{"id":"08nBy3wKxNk9"},"source":["# Converting the strings in 'product_category_tree' column in 6 categ columns\n","\n","# determining the maximum tree depth of categories\n","ser_depth = df['product_category_tree'].apply(lambda x: x.count('>>'))\n","max_depth = ser_depth.max()\n","\n","def str_cleaning(ind, my_str, name_level_cols):\n","    my_str = my_str.replace(\"[\\\"\", \"\").replace(\"\\\"]\", \"\")\n","    tab_str = my_str.split(\">>\")\n","    size_tab_str = len(tab_str)\n","    tup_str = tuple([tab_str[i].strip() if i<size_tab_str else \"\" \\\n","                     for i in np.arange(max_depth) ])\n","    return tup_str\n","\n","name_level_cols = ['cat_level_'+str(i) for i in np.arange(max_depth)]\n","ser_tuple = df['product_category_tree']\\\n","    .apply(lambda s: str_cleaning(s.index, s, name_level_cols))\n","df_cat_level = pd.DataFrame([[a,'/'.join([a,b]),'/'.join([a,b,c]),\n","                              '/'.join([a,b,c,d]),'/'.join([a,b,c,d,e]),\n","                              '/'.join([a,b,c,d,e,f])] \\\n","                             for a,b,c,d,e,f in ser_tuple.values],\n","                            columns=name_level_cols, index=df.index)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"utzO4D0L0Mwg"},"source":["# Create a dataframe for images\n","\n","df_image = df[['product_name', 'description']].copy('deep')\n","df_image['category'] = \\\n","    df_cat_level['cat_level_0'].replace({'Home Furnishing': 'Furnishing',\n","                                         'Baby Care': 'Baby', \n","                                         'Watches': 'Watches',\n","                                         'Home Decor & Festive Needs': 'Decor',\n","                                         'Kitchen & Dining': 'Kitchen',\n","                                         'Beauty and Personal Care': 'Beauty',\n","                                         'Computers': 'Computers'})\n","indexes = df_image.index"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iwXHJlEdGl5K"},"source":["### 0.3 Images properties"]},{"cell_type":"code","metadata":{"id":"pvvv8zZI0uvX"},"source":["from PIL import Image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6hbvHrL1kznK"},"source":["# # Get properties (size, mode) of each image, put it in a dataframe\n","\n","# wh_tab, mode_tab = [], []\n","# for ind in indexes:\n","#     img = Image.open(\"../DATA/Images/\"+ind+\".jpg\")\n","#     mode_tab.append(img.mode) \n","#     wh_tab.append(list(img.size))\n","\n","# df_image['mode_img'] = mode_tab\n","# df_image[['w_img', 'h_img']] = wh_tab"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2h9lHBvsfEKi"},"source":["## 1 Image pre-processing"]},{"cell_type":"markdown","metadata":{"id":"-VEYv7flfOX3"},"source":["### 1.0 Vectorization and resizing of images"]},{"cell_type":"code","metadata":{"id":"A23P9soWjJml"},"source":["from PIL import ImageOps\n","from PIL.ImageFilter import GaussianBlur\n","# étirement de l'histogramme (ajustement de la luminosité)\n","img_auto_bright = ImageOps.autocontrast(img)\n","# ajustemeent du contraste\n","img_auto_contr = ImageOps.equalize(img)\n","# floutage / Débruitage\n","mon_filtre = GaussianBlur(radius=2)\n","img_blur = img.filter(mon_filtre)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nYBuDmWKZWD-"},"source":["Load each image, resizes to 224*224 and store the values of pixel in HSV in the dataframe"]},{"cell_type":"code","metadata":{"id":"oJUNcwY3VFNC","executionInfo":{"status":"error","timestamp":1604678792532,"user_tz":-60,"elapsed":576,"user":{"displayName":"Maryse Muller","photoUrl":"","userId":"13230828717959946182"}},"outputId":"6ee0ba3e-a0f8-4d2d-ae46-d78edb43b8a8","colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["from PIL import Image\n","import colorsys\n","\n","rgb_to_hsv = np.vectorize(colorsys.rgb_to_hsv)\n","\n","size = 224\n","\n","# df_temp = pd.DataFrame([])\n","dict_images = {}\n","li_cols = [ l+'_'+str(i) for l in ['H', 'S', 'V']\\\n","           for i in range(size*size)]\n","\n","for i, ind in enumerate(indexes):\n","    if i%100==0: print(i)\n","    img = np.array(Image.open(\"../DATA/Images/\"+ind+\".jpg\"))\n","    img = preproc_image(img, size=size, fill_col=(255,255,255),\n","                  autocontrast = False, equalize=False,\n","                  gauss_blur = None, interpolation=cv2.INTER_AREA)\n","    dict_images[ind] = img\n","    # img_ravel = np.stack(np.array(rgb_to_hsv(img[:,:,0],\n","    #                                          img[:,:,1],\n","    #                                          img[:,:,2])), 0).ravel()\n","    # ser = pd.Series(img_ravel, index = li_cols, name=ind).to_frame()\n","    # df_temp = pd.concat([df_temp, ser.T], axis=0)\n","\n","# df_image = pd.concat([df_image, df_temp], axis=1)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-09dd2873246f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcolorsys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrgb_to_hsv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolorsys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb_to_hsv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}]},{"cell_type":"code","metadata":{"id":"cRv37yAQZnnv"},"source":["# import dill\n","# dill.dump(dict_images, open('dict_images.pkl', mode='wb'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wUpL56KYhW83"},"source":["import dill\n","df_image = dill.load(open('df_image.pkl', mode='rb'))\n","dict_images = dill.load(open('dict_images.pkl', mode='rb'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LEZjoRYUUED-"},"source":["Visualisation séparée des trois canaux (Hue, Saturation, Value)"]},{"cell_type":"code","metadata":{"id":"e_SgI-cBqSbv"},"source":["# fig = plt.figure(figsize=(10,4))\n","# li_n = []\n","# for im, color, title, i in zip([img_h, img_s, img_v],\n","#                                 ['red', 'blue', 'black'],\n","#                                 ['Hue', 'Saturation', 'Value'],\n","#                                 range(1,4)):\n","#     ax1 = fig.add_subplot(2,3,i)\n","#     ax1.imshow(im, cmap='Greys')\n","#     ax1.set(xlim=(0,255))\n","#     ax1.set_title(title, fontweight='bold')\n","#     ax2 = fig.add_subplot(2,3,i+3)\n","#     n, bins, patches = ax2.hist(im.flatten(), color=color, bins=range(256))\n","#     li_n.append(n)\n","# plt.tight_layout(rect=[0,0,1,0.92])\n","# plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rtpfTnmAe023"},"source":["# Creation of a bag of visual words"]},{"cell_type":"markdown","metadata":{"id":"HHUJWtOLfCLg"},"source":["### Load train and test images into dictionaries."]},{"cell_type":"code","metadata":{"id":"vnuSXJSKHOFR"},"source":["import numpy as np\n","import cv2\n","import os\n","from scipy import ndimage\n","from scipy.spatial import distance\n","from sklearn.cluster import KMeans"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eBSgCzYyK-3V"},"source":["# plt.imshow(dict_images['7b72c92c2f6c40268628ec5f14c6d590'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x8kFfV3QTcTZ"},"source":["from PIL.Image import fromarray"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y3JDAfSyfLFP"},"source":["### Extracts local features from images using SIFT.\n","\n","The below function returns an array whose first index holds a list that holds all local features from all images without an order. This is our visual dictionary. And the second index holds the sift vectors dictionary which holds the descriptors but this is separated class by class"]},{"cell_type":"code","metadata":{"id":"gSsNyADDezmS"},"source":["# Creates descriptors using sift \n","# Takes one parameter that is images dictionary\n","# Return an array whose first index holds the decriptor_list without an order\n","# And the second index holds the sift_vectors dictionary which holds the descriptors but this is seperated class by class\n","def sift_features(images):\n","    sift_vectors = {}\n","    descriptor_list = []\n","    sift = cv2.xfeatures2d.SIFT_create()\n","    for key,img in images.items():\n","        print(key)\n","        features = []\n","        print(img.shape)\n","        # img = Image.fromarray(img)\n","        kp, des = sift.detectAndCompute(img,None)\n","        descriptor_list.extend(des)\n","        features.append(des)\n","        sift_vectors[key] = features\n","    return [descriptor_list, sift_vectors]\n","\n","# def get_descriptors(image_path):\n","#     # load image and convert it to grayscale\n","#     img_gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","#     # detect key points and descriptors\n","#     keypoints, descriptors = model.detectAndCompute(img_gray, None)\n","#     # returns keypoints and descriptors\n","#     return keypoints, descriptors"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cwBsptXbEqaY"},"source":["import cv2\n","detector =cv2.xfeatures2d.SIFT_create()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1U998Yfjex11"},"source":["sifts = sift_features(dict_images) \n","# Takes the descriptor list which is unordered one\n","descriptor_list = sifts[0] \n","# Takes the sift features that is seperated class by class for train data\n","all_bovw_feature = sifts[1] \n","# Takes the sift features that is seperated class by class for test data\n","# test_bovw_feature = sift_features(test)[1] "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PjPSue4xwSLw"},"source":["STOP"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x_82JM5hexuY"},"source":["df_image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gxpo2FAsfW6R"},"source":["### Find the visual words \n","\n","Send the visual dictionary to the k-means clustering algorithm and find the visual words which are center points."]},{"cell_type":"code","metadata":{"id":"Dxa_44gSexkp"},"source":["\n","# A k-means clustering algorithm who takes 2 parameter which is number \n","# of cluster(k) and the other is descriptors list(unordered 1d array)\n","# Returns an array that holds central points.\n","def kmeans(k, descriptor_list):\n","    kmeans = KMeans(n_clusters = k, n_init=10)\n","    kmeans.fit(descriptor_list)\n","    visual_words = kmeans.cluster_centers_ \n","    return visual_words\n","    \n","# Takes the central points which is visual words    \n","visual_words = kmeans(150, descriptor_list) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kniJki7wexee"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q0IIyD_TflAe"},"source":["### Create histograms"]},{"cell_type":"code","metadata":{"id":"CjMzjwzUewdG"},"source":["\n","# Takes 2 parameters. The first one is a dictionary that holds the descriptors that are separated class by class \n","# And the second parameter is an array that holds the central points (visual words) of the k means clustering\n","# Returns a dictionary that holds the histograms for each images that are separated class by class. \n","def image_class(all_bovw, centers):\n","    dict_feature = {}\n","    for key,value in all_bovw.items():\n","        category = []\n","        for img in value:\n","            histogram = np.zeros(len(centers))\n","            for each_feature in img:\n","                ind = find_index(each_feature, centers)\n","                histogram[ind] += 1\n","            category.append(histogram)\n","        dict_feature[key] = category\n","    return dict_feature\n","    \n","# Creates histograms for train data    \n","bovw_train = image_class(all_bovw_feature, visual_words) \n","# Creates histograms for test data\n","bovw_test = image_class(test_bovw_feature, visual_words) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kOldNQZifwUT"},"source":["## Predict classes of the test images with k-NN function."]},{"cell_type":"code","metadata":{"id":"EO7aTkMIS0CA"},"source":["\n","# 1-NN algorithm. We use this for predict the class of test images.\n","# Takes 2 parameters. images is the feature vectors of train images and tests is the feature vectors of test images\n","# Returns an array that holds number of test images, number of correctly predicted images and records of class based images respectively\n","def knn(images, tests):\n","    num_test = 0\n","    correct_predict = 0\n","    class_based = {}\n","    \n","    for test_key, test_val in tests.items():\n","        class_based[test_key] = [0, 0] # [correct, all]\n","        for tst in test_val:\n","            predict_start = 0\n","            #print(test_key)\n","            minimum = 0\n","            key = \"a\" #predicted\n","            for train_key, train_val in images.items():\n","                for train in train_val:\n","                    if(predict_start == 0):\n","                        minimum = distance.euclidean(tst, train)\n","                        #minimum = L1_dist(tst,train)\n","                        key = train_key\n","                        predict_start += 1\n","                    else:\n","                        dist = distance.euclidean(tst, train)\n","                        #dist = L1_dist(tst,train)\n","                        if(dist < minimum):\n","                            minimum = dist\n","                            key = train_key\n","            \n","            if(test_key == key):\n","                correct_predict += 1\n","                class_based[test_key][0] += 1\n","            num_test += 1\n","            class_based[test_key][1] += 1\n","            #print(minimum)\n","    return [num_test, correct_predict, class_based]\n","    \n","# Call the knn function    \n","results_bowl = knn(bovw_train, bovw_test) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XvQ3iUm7f3qY"},"source":["## Calculate the accuracy"]},{"cell_type":"code","metadata":{"id":"-wU3EN_hft6l"},"source":["\n","# Calculates the average accuracy and class based accuracies.  \n","def accuracy(results):\n","    avg_accuracy = (results[1] / results[0]) * 100\n","    print(\"Average accuracy: %\" + str(avg_accuracy))\n","    print(\"\\nClass based accuracies: \\n\")\n","    for key,value in results[2].items():\n","        acc = (value[0] / value[1]) * 100\n","        print(key + \" : %\" + str(acc))\n","        \n","# Calculates the accuracies and write the results to the console.       \n","accuracy(results_bowl) \n","view rawaccuracy.py hosted with ❤ by GitHub"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E5hLaPG7ftz2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dSYOBBNTftxY"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fgxXRjFKftoD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ve8yUAKzftlz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0vGbRGVHftgQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4h-oUBsOftay"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3LvGOowR5Jh9"},"source":["# Exportation"]},{"cell_type":"markdown","metadata":{"id":"yyrC3LXL5MGu"},"source":["Now we export the dataset of aggregated orders in a .csv file."]},{"cell_type":"code","metadata":{"id":"SmvecmLIQlAu"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"am7VHtr9Qk-C"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dRCOqxQGQk7c"},"source":[""],"execution_count":null,"outputs":[]}]}